\begin{abstract}
  We present techniques for speeding up the test-time evaluation of
  large convolutional networks, designed for object recognition
  tasks. These models deliver impressive accuracy, but each image
  evaluation requires millions of floating point operations, making
  their deployment on smartphones and Internet-scale clusters
  problematic. The computation is dominated by the convolution
  operations in the lower layers of the model. We exploit the redundancy
  present within the convolutional filters to derive
  approximations that significantly reduce the required
  computation. Using large state-of-the-art models, we demonstrate
  speedups of convolutional layers on both CPU and GPU by a factor of $2\times$, while keeping the accuracy
  within $1\%$ of the original model.
\end{abstract}

\section{Introduction}

Large neural networks have recently demonstrated impressive
performance on a range of speech and vision tasks. However, the size of
these models can make their deployment at test time problematic. For
example, mobile computing platforms are limited in their CPU speed,
memory and battery life. At the other end of the spectrum,
Internet-scale deployment of these models requires thousands of
servers to process the 100's of millions of images per day. The
electrical and cooling costs of these servers required is significant.
Training large neural networks can take weeks, or even
months. This hinders research and consequently there have been
extensive efforts devoted to speeding up training procedure.  However,
there are relatively few efforts aimed at improving the {\em test-time}
performance of the models. 

 We consider convolutional neural networks (CNNs) used for computer vision tasks, since
they are large and widely used in commercial applications. 
These networks typically require a huge number of parameters ($\sim 10^{7}$ in \cite{sermanet2013overfeat})
to produce state-of-the-art results. 
While, these networks tend to be hugely over parameterized \cite{denil2013predicting}, this redundancy seems necessary in order
to overcome a highly non-convex optimization \cite{hinton2012improving}. 
As a byproduct, the resulting network wastes computing resources.
In this paper we show that this redundancy can be 
exploited with linear compression techniques,
resulting in significant speedups for the evaluation of {\em trained}
large scale networks, with minimal compromise to performance.
In particular, we concentrate on the lower convolutional layers, which 
typically dominate the evaluation cost. 

We follow a relatively simple strategy: we start by compressing each 
convolutional layer by finding an appropriate low-rank approximation, 
and then we fine-tune the upper layers until the prediction performance 
is restored. We consider several elementary tensor decompositions based 
on singular value decompositions, as well as filter clustering methods to take advantage of similarities between learned features. 

In summary, our main contributions are the following:
We present a collection of generic methods to exploit the redundancy inherent in deep CNNs.
We report experiments on state-of-the-art Imagenet CNNs, showing empirical speedups on 
convolutional layers by a factor of $2-3\times$ and a reduction of parameters in fully connected layers by a factor of $5-10\times$.


%Within these models, most of the time ($\sim90\%$) is spent in the
%convolution operations in the lower layers of the model. The remaining
%operations: pooling, contrast normalization and the upper
%fully-connected layers collectively take up the remaning $10\%$.

%We present several novel methods for speeding up the convolution
%operations. They are based on various low-dimensional approximations of convolution
%operators (which are 4-dimensional tensors), and exploit sparsity to
%deliver speedups in performance. Viability of methods is architecture 
%dependent, and speedup by factor of $2$ is quite achievable without fine-tuning.
%However, a much larger speedup should be attainable if the models were
%trained for a few more epochs after imposing the filter approximation.

%Neural networks are stacked linear transforms alternated with simple
%point-wise non-linearities. From mathematical perspective, we have a good understanding
%of linear operators, however properties of composed operators are much more
%difficult to understand. Our studies of filter compressibility reveal some of underlying
%low-dimensional structure. Effectively, it decreases number of parameters, and
%potentially might lead to better model generalization if used during training.
%We observe some indications that it is indeed feasible. In particular,
%the first layer filters look ``cleaner'' after approximation and can,
%on occasion, yield a slightly lower test error than the original versions,
%provided the approximations are mild. 

 \noindent \textbf{Notation:} Convolution weights can be described as
 a $4$-dimensional tensor: $W \in \mathbb{R}^{C \times X \times Y
   \times F}$. $C$ is the number of number of input channels, $X$ and
 $Y$ are the spatial dimensions of the kernel, and $F$ is the target
 number of feature maps. 
 It is common for the first convolutional layer to have a stride associated with the kernel which we denote by $\Delta$.  Let $I \in \mathbb{R}^{C \times N \times M}$
 denote an input signal where $C$ is the number of input maps, and $N$
 and $M$ are the spatial dimensions of the maps.  The target value, $T
 = I \ast W$, of a generic convolutional layer, with $\Delta = 1$, for a particular output
 feature, $f$, and spatial location, $(x, y)$, is
\begin{align*}
\label{convlayereq}
T(f,x,y) = \sum_{c=1}^C \sum_{x'=1}^{X} \sum_{y'=1}^{Y} I(c,x-x',y-y') W(c,x',y',f)
\end{align*}
Moreover, we define $W_C \in \mathbb{R}^{C \times (XYF)}$, and $W_F \in \mathbb{R}^{(CXY) \times F}$, 
and $W_S \in \mathbb{R}^{C \times (XY) \times F}$ to be the folded, with respect to different dimensions, versions of $W$.

If $X$ is a tensor, $\|X \|$ denotes its operator norm, and $\|X \|_F$ denotes its Frobenius norm.
If $v$ is a vector, $\|v \|$ denotes its Euclidean norm.

\section{Related Work}
\label{relwork}

Vanhoucke \etal \cite{vanhoucke2011improving} explored the
properties of CPUs to speed up execution.  They present many solutions
specific to Intel and AMD CPUs, however some of their techniques are
general enough to be used for any type of processor.  They describe
how to align memory, and use SIMD operations (vectorized operations on
CPU) to boost the efficiency of matrix multiplication.  Additionally, they
propose the linear quantization of the network weights and input. This
involves representing weights as 8-bit integers (range
$[-127, 128]$), rather than 32-bit floats. This approximation is
similar in spirit to our approach, but differs in that it is applied
to each weight element independently. By contrast, our approximation approach models
the structure within each filter. Potentially, the two approaches
could be used in conjunction. 

The most expensive operations in CNNs are the
convolutions in the first few layers. The complexity of this operation
is linear in the area of the receptive field of the filters, which is
relatively large for these layers.  However, Mathieu \etal \cite{mathieu2013fast} have shown that convolution can be
efficiently computed in Fourier domain, where it becomes element-wise
multiplication (and there is no cost associated with size of receptive
field). They report a forward-pass speed up of around $2\times$ for
convolution layers in state-of-the-art models. Importantly, the FFT method can
be used jointly with most of the techniques presented in this paper.

The use of low-rank approximations in our approach is inspired by work
of Denil \etal \cite{denil2013predicting} who demonstrate the redundancies in neural
network parameters. They show that the weights within a layer can be
accurately predicted from a small (e.g. $\sim 5\%$) subset of them. This
indicates that neural networks are heavily over-parametrized.  All the
methods presented here focus on exploiting the linear structure of this
over-parametrization.

Finally, a recent preprint \cite{zisserman14} also exploits low-rank decompositions
of convolutional tensors to speed up the evaluation of CNNs, applied to scene text character
recognition. This work was developed simultaneously with ours, and provides 
further evidence that such techniques can be applied to a variety of architectures 
and tasks. 
Out work differs in several ways. 
First, we consider a significantly larger model. 
This makes it more challenging to compute efficient approximations since there are more layers to propagate through and thus a greater opportunity for error accumulate. 
Second, we present different compression techniques for the hidden convolutional layers and provide a method of compressing the first convolution. Finally, we present GPU results in addition to CPU results. 

